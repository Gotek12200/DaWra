train_features <- train_clean %>% select(-score)
test_features <- test_clean %>% select(-score)
predicted_scores
# Train and test features
train_features <- train_clean %>% select(-score)
test_features <- test %>% select(-score)
View(train_clean)
train_clean$score
train_clean %>% select(-score)
View(test)
View(test)
# Train and test features
train_features <- train_clean %>% select(-score)
test_features <- test %>% select(-train_traiscore)
# Train and test features
train_features <- train_clean %>% select(-score)
# Train target (score)
train_target <- train_clean$score
# Run KNN regression with k = 5
knn_result <- knn.reg(
train = train_features,
y = train_target,
k = 5
)
library(FNN)
library(class)
# Train and test features
train_features <- train_clean %>% select(-score)
# Train target (score)
train_target <- train_clean$score
# Run KNN regression with k = 5
knn_result <- knn.reg(
train = train_features,
y = train_target,
k = 5
)
install.packages('FNN')
library(class)
# Train and test features
train_features <- train_clean %>% select(-score)
# Train target (score)
train_target <- train_clean$score
# Run KNN regression with k = 5
knn_result <- knn.reg(
train = train_features,
y = train_target,
k = 5
)
library(FNN)
# Train and test features
train_features <- train_clean %>% select(-score)
# Train target (score)
train_target <- train_clean$score
# Run KNN regression with k = 5
knn_result <- knn.reg(
train = train_features,
y = train_target,
k = 5
)
library(KNN)
library(KKN)
library(kknn)
intall.packages('KKNN')
install.packages('KKNN')
install.packages('kknn')
library(kknn)
model <- train.kknn(
score ~ .,
data = your_data,
kmax = 10
)
model <- train.kknn(
score ~ .,
data = train_clean,
kmax = 10
)
pred <- predict(model, newdata =test)
pred
model
# Get column names for the missing values for data_clean
columns <- colnames(data_clean)
# Get column names for the missing values for train_clean
columns <- colnames(data_clean)
# Get column names for the missing values for train_clean
columns <- colnames(train_clean)
for (col in columns) {
# Count missing values in the current column
missing_count <- sum(is.na(train_clean[[col]]))
# If there are missing values, print the count
if (missing_count > 0) {
cat("Column", col, "has", missing_count, "missing values.\n")
}
}
# Check for outliers
for (col in names(train_clean)) {
# Extract the column
values <- train_clean[[col]]
# Compute Q1, Q3, and IQR
Q1 <- quantile(values, 0.25, na.rm = TRUE)
Q3 <- quantile(values, 0.75, na.rm = TRUE)
IQR <- Q3 - Q1
# Define outlier thresholds
lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR
# Find outlier indices
outlier_indices <- which(values < lower_bound | values > upper_bound)
# Print results if outliers are found
if (length(outlier_indices) > 0) {
cat("Column", col, "has", length(outlier_indices), "outliers.\n")
}
}
# Check for outliers
def stat_outliers (col):
# Function to find and plot outliers using 3*std rule
def stat_outliers(col):
# Function to find and plot outliers using 3*std rule
def stat_outliers(col):
# Loop through all numeric columns in train_clean
for (col_name in names(train_clean)) {
column <- train_clean[[col_name]]
# Check if column is numeric
if (is.numeric(column)) {
# Calculate mean and standard deviation
m <- mean(column, na.rm = TRUE)
s <- sd(column, na.rm = TRUE)
# Find outliers: values more than 3 standard deviations from the mean
outlier_indices <- which(abs(column - m) > 3 * s)
# Print results if outliers found
if (length(outlier_indices) > 0) {
cat("Outliers found in column:", col_name, "\n")
cat("Indices:", outlier_indices, "\n")
cat("Values:", column[outlier_indices], "\n\n")
# Optional: Plot with outliers highlighted
plot(column, main = paste("Outliers in", col_name),
col = ifelse(1:length(column) %in% outlier_indices, "red", "black"),
pch = ifelse(1:length(column) %in% outlier_indices, 19, 1),
ylab = col_name, xlab = "Index")
legend("topright", legend = c("Outlier", "Normal"), col = c("red", "black"), pch = c(19, 1))
}
}
}
# Loop through numeric columns
for (col_name in names(train_clean)) {
column <- train_clean_no_outliers[[col_name]]
if (is.numeric(column)) {
m <- mean(column, na.rm = TRUE)
s <- sd(column, na.rm = TRUE)
# Find indices of outliers
outlier_indices <- which(abs(column - m) > 3 * s)
if (length(outlier_indices) > 0) {
cat("Removing outliers in column:", col_name, "\n")
# Remove rows with outliers in this column
train_clean_no_outliers <- train_clean_no_outliers[-outlier_indices, ]
}
}
}
# Create a copy of the data to clean
train_clean_no_outliers <- train_clean
# Loop through numeric columns
for (col_name in names(train_clean)) {
column <- train_clean_no_outliers[[col_name]]
if (is.numeric(column)) {
m <- mean(column, na.rm = TRUE)
s <- sd(column, na.rm = TRUE)
# Find indices of outliers
outlier_indices <- which(abs(column - m) > 3 * s)
if (length(outlier_indices) > 0) {
cat("Removing outliers in column:", col_name, "\n")
# Remove rows with outliers in this column
train_clean_no_outliers <- train_clean_no_outliers[-outlier_indices, ]
}
}
}
#KNN regression
library(kknn)
model <- train.kknn(
score ~ .,
data = train_clean_no_outliers,
kmax = 10
)
pred <- predict(model, newdata =test)
print("Outliers in column ", col, " are: ", outliers)
pred
#check for outliers with the statistical approach
for (col_name in names(train_clean)) {
column <- train_clean[[col_name]]
# Check if column is numeric
if (is.numeric(column)) {
# Calculate mean and standard deviation
m <- mean(column, na.rm = TRUE)
s <- sd(column, na.rm = TRUE)
# Find outliers: values more than 3 standard deviations from the mean
outlier_indices <- which(abs(column - m) > 3 * s)
# Print results if outliers found
if (length(outlier_indices) > 0) {
cat("Outliers found in column:", col_name, "\n")
cat("Indices:", outlier_indices, "\n")
cat("Values:", column[outlier_indices], "\n\n")
# Plot with outliers highlighted
plot(column, main = paste("Outliers in", col_name),
col = ifelse(1:length(column) %in% outlier_indices, "red", "black"),
pch = ifelse(1:length(column) %in% outlier_indices, 19, 1),
ylab = col_name, xlab = "Index")
legend("topright", legend = c("Outlier", "Normal"), col = c("red", "black"), pch = c(19, 1))
}
}
}
# Create a logical vector to mark rows to keep (start with all TRUE)
rows_to_keep <- rep(TRUE, nrow(train_clean))
# Loop through numeric columns
for (col_name in names(train_clean)) {
column <- train_clean[[col_name]]
if (is.numeric(column)) {
m <- mean(column, na.rm = TRUE)
s <- sd(column, na.rm = TRUE)
# Identify outlier indices in this column
outlier_indices <- which(abs(column - m) > 3 * s)
if (length(outlier_indices) > 0) {
# Mark these rows as FALSE (to be removed)
rows_to_keep[outlier_indices] <- FALSE
}
}
}
# Subset the data to remove outliers in any numeric column
train_clean_no_outliers <- train_clean[rows_to_keep, ]
#KNN regression
library(kknn)
model <- train.kknn(
score ~ .,
data = train_clean_no_outliers,
kmax = 10
)
pred <- predict(model, newdata =test)
pred
#KNN regression with the outliers
library(kknn)
model <- train.kknn(
score ~ .,
data = train_clean,
kmax = 10
)
pred <- predict(model, newdata =test)
#KNN regression with the outliers
library(kknn)
model <- train.kknn(
score ~ .,
data = train_clean,
kmax = 10
)
pred_with_outliers<- predict(model, newdata =test)
pred_with_outliers
plot(pred, type = "b", col = "blue", pch = 19,
main = "Predictions: With vs Without Outliers",
xlab = "Observation", ylab = "Predicted Score", ylim = range(c(pred, pred_with_outliers)))
lines(pred_with_outliers, type = "b", col = "red", pch = 17)
legend("bottomright", legend = c("Without Outliers", "With Outliers"),
col = c("blue", "red"), pch = c(19, 17))
differences <- pred - pred_with_outliers
summary(differences)
mean(abs(differences))
#check for outliers with the statistical approach
for (col_name in names(train_clean)) {
column <- train_clean[[col_name]]
# Check if column is numeric
if (is.numeric(column)) {
# Calculate mean and standard deviation
m <- mean(column, na.rm = TRUE)
s <- sd(column, na.rm = TRUE)
# Find outliers: values more than 3 standard deviations from the mean
outlier_indices <- which(abs(column - m) > 3 * s)
# Print results if outliers found
if (length(outlier_indices) > 0) {
cat("Outliers found in column:", col_name, "\n")
cat("Indices:", outlier_indices, "\n")
cat("Values:", column[outlier_indices], "\n\n")
# Plot with outliers highlighted
plot(column, main = paste("Outliers in", col_name),
col = ifelse(1:length(column) %in% outlier_indices, "red", "black"),
pch = ifelse(1:length(column) %in% outlier_indices, 19, 1),
ylab = col_name, xlab = "Index")
legend("topright", legend = c("Outlier", "Normal"), col = c("red", "black"), pch = c(19, 1))
}
}
}
# Create a logical vector to mark rows to keep (start with all TRUE)
rows_to_keep <- rep(TRUE, nrow(train_clean))
# Loop through numeric columns
for (col_name in names(train_clean)) {
column <- train_clean[[col_name]]
if (is.numeric(column)) {
m <- mean(column, na.rm = TRUE)
s <- sd(column, na.rm = TRUE)
# Identify outlier indices in this column
outlier_indices <- which(abs(column - m) > 3 * s)
if (length(outlier_indices) > 0) {
# Mark these rows as FALSE (to be removed)
rows_to_keep[outlier_indices] <- FALSE
}
}
}
# Subset the data to remove outliers in any numeric column
train_clean_no_outliers <- train_clean[rows_to_keep, ]
#KNN regression without the outliers
library(kknn)
model <- train.kknn(
score ~ .,
data = train_clean_no_outliers,
kmax = 10
)
pred <- predict(model, newdata =test)
#KNN regression with the outliers
library(kknn)
model <- train.kknn(
score ~ .,
data = train_clean,
kmax = 10
)
pred_with_outliers <- predict(model, newdata=test)
#Check the impact of outliers
differences <- pred - pred_with_outliers
summary(differences)
#check for outliers with the statistical approach
for (col_name in names(train_clean)) {
column <- train_clean[[col_name]]
# Check if column is numeric
if (is.numeric(column)) {
outlier_indices <- which(abs(column - m) > 3 * s)
# Print results if outliers found
if (length(outlier_indices) > 0) {
cat("Outliers found in column:", col_name, "\n")
cat("Indices:", outlier_indices, "\n")
cat("Values:", column[outlier_indices], "\n\n")
# Plot with outliers highlighted
plot(column, main = paste("Outliers in", col_name),
col = ifelse(1:length(column) %in% outlier_indices, "red", "black"),
pch = ifelse(1:length(column) %in% outlier_indices, 19, 1),
ylab = col_name, xlab = "Index")
legend("topright", legend = c("Outlier", "Normal"), col = c("red", "black"), pch = c(19, 1))
}
}
}
# Create a logical vector to mark rows to keep (start with all TRUE)
rows_to_keep <- rep(TRUE, nrow(train_clean))
# Loop through numeric columns
for (col_name in names(train_clean)) {
column <- train_clean[[col_name]]
if (is.numeric(column)) {
m <- mean(column, na.rm = TRUE)
s <- sd(column, na.rm = TRUE)
# Identify outlier indices in this column
outlier_indices <- which(abs(column - m) > 3 * s)
if (length(outlier_indices) > 0) {
# Mark these rows as FALSE (to be removed)
rows_to_keep[outlier_indices] <- FALSE
}
}
}
# Subset the data to remove outliers in any numeric column
train_clean_no_outliers <- train_clean[rows_to_keep, ]
#KNN regression without the outliers
library(kknn)
model <- train.kknn(
score ~ .,
data = train_clean_no_outliers,
kmax = 10
)
pred <- predict(model, newdata =test)
#KNN regression with the outliers
library(kknn)
model <- train.kknn(
score ~ .,
data = train_clean,
kmax = 10
)
pred_with_outliers <- predict(model, newdata=test)
#Check the impact of outliers
differences <- pred - pred_with_outliers
summary(differences)
rows_to_keep <- rep(TRUE, nrow(train_clean))
if (length(outlier_indices) > 0) {
cat("Outliers found in column:", col_name, "\n")
cat("Indices:", outlier_indices, "\n")
cat("Values:", column[outlier_indices], "\n\n")
#check for outliers with the statistical approach
for (col_name in names(train_clean)) {
column <- train_clean[[col_name]]
# Check if column is numeric
if (is.numeric(column)) {
outlier_indices <- which(abs(column - m) > 3 * s)
# Print results if outliers found
if (length(outlier_indices) > 0) {
cat("Outliers found in column:", col_name, "\n")
cat("Indices:", outlier_indices, "\n")
cat("Values:", column[outlier_indices], "\n\n")
# Plot with outliers highlighted
plot(column, main = paste("Outliers in", col_name),
col = ifelse(1:length(column) %in% outlier_indices, "red", "black"),
pch = ifelse(1:length(column) %in% outlier_indices, 19, 1),
ylab = col_name, xlab = "Index")
legend("topright", legend = c("Outlier", "Normal"), col = c("red", "black"), pch = c(19, 1))
}
}
}
# Create a logical vector to mark rows to keep (start with all TRUE)
rows_to_keep <- rep(TRUE, nrow(train_clean))
# Loop through numeric columns
for (col_name in names(train_clean)) {
column <- train_clean[[col_name]]
if (is.numeric(column)) {
m <- mean(column, na.rm = TRUE)
s <- sd(column, na.rm = TRUE)
# Identify outlier indices in this column
outlier_indices <- which(abs(column - m) > 3 * s)
if (length(outlier_indices) > 0) {
# Mark these rows as FALSE (to be removed)
rows_to_keep[outlier_indices] <- FALSE
}
}
}
# Subset the data to remove outliers in any numeric column
train_clean_no_outliers <- train_clean[rows_to_keep, ]
#KNN regression without the outliers
library(kknn)
model <- train.kknn(
score ~ .,
data = train_clean_no_outliers,
kmax = 10
)
pred <- predict(model, newdata =test)
#KNN regression with the outliers
library(kknn)
model <- train.kknn(
score ~ .,
data = train_clean,
kmax = 10
)
pred_with_outliers <- predict(model, newdata=test)
#Check the impact of outliers
differences <- pred - pred_with_outliers
summary(differences)
differences
# Load necessary packages
library(tidyverse)
library(ggplot2)
library(dplyr)
library(readr)
library(corrplot)
library(GGally)
library(janitor)
# Load data
train <- readRDS("train.rds")
test <- readRDS("test.rds")
# Preview the data
glimpse(train)
summary(train)
#Missing Values
train %>% summarise(across(everything(), ~sum(is.na(.)))) %>%
pivot_longer(everything(), names_to = "variable", values_to = "missing_count") %>%
arrange(desc(missing_count))
ggplot(train, aes(x = score)) +
geom_histogram(fill = "skyblue", color = "white", bins = 20) +
theme_minimal() +
labs(title = "Distribution of Student Scores",
x = "Score", y = "Count")
# Summary statistics for numerical variables
train %>%
select(where(is.numeric)) %>%
summary()
# Compute correlation matrix for numeric variables
num_vars <- train %>% select(where(is.numeric)) %>% select(-score)
cor_mat <- cor(num_vars, use = "pairwise.complete.obs")
corrplot(cor_mat, method = "color", type = "upper", tl.cex = 0.8)
# Correlation of each numeric variable with score
correlations <- train %>%
select(where(is.numeric)) %>%
cor(use = "pairwise.complete.obs") %>%
as.data.frame() %>%
rownames_to_column("Variable") %>%
select(Variable, score) %>%
arrange(desc(abs(score)))
head(correlations, 10)
# Handle missing values
train_clean <- train %>%
mutate(across(where(is.numeric), ~ifelse(is.na(.), mean(., na.rm = TRUE), .)))
# Convert categorical variables to factors
train_clean <- train_clean %>%
mutate(across(where(is.character), as.factor))
glimpse(train_clean)
#check for outliers with the statistical approach
for (col_name in names(train_clean)) {
column <- train_clean[[col_name]]
# Check if column is numeric
if (is.numeric(column)) {
# Calculate mean and standard deviation
m <- mean(column, na.rm = TRUE)
s <- sd(column, na.rm = TRUE)
# Find outliers: values more than 3 standard deviations from the mean
outlier_indices <- which(abs(column - m) > 3 * s)
# Print results if outliers found
if (length(outlier_indices) > 0) {
cat("Outliers found in column:", col_name, "\n")
cat("Indices:", outlier_indices, "\n")
cat("Values:", column[outlier_indices], "\n\n")
# Plot with outliers highlighted
plot(column, main = paste("Outliers in", col_name),
col = ifelse(1:length(column) %in% outlier_indices, "red", "black"),
pch = ifelse(1:length(column) %in% outlier_indices, 19, 1),
ylab = col_name, xlab = "Index")
legend("topright", legend = c("Outlier", "Normal"), col = c("red", "black"), pch = c(19, 1))
}
}
}
