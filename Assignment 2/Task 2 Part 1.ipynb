{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:29.890524Z",
     "start_time": "2025-10-06T20:42:29.858078Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Levenshtein as lev\n",
    "from py_stringmatching import similarity_measure as sm"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:29.956584Z",
     "start_time": "2025-10-06T20:42:29.899330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Part 1\n",
    "# a. Ignore the pub_id.\n",
    "acm = pd.read_csv(\"ACM.csv\")\n",
    "dblp = pd.read_csv(\"DBLP2.csv\", encoding=\"latin1\")\n",
    "acm1 = pd.read_csv(\"ACM.csv\")\n",
    "dblp1 = pd.read_csv(\"DBLP2.csv\", encoding=\"latin1\")\n",
    "# acm1 = acm.drop(columns=['id'], errors='ignore')\n",
    "# dblp1 = dblp.drop(columns=['id'], errors = 'ignore')"
   ],
   "id": "1f8171e0fa1f508e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:29.979218Z",
     "start_time": "2025-10-06T20:42:29.964723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# b. Change all alphabetical characters into lowercase.\n",
    "acm1['title'] = acm1['title'].str.lower()\n",
    "dblp1['title'] = dblp1['title'].str.lower()\n",
    "print(acm1.head(10)) #to double-check correctness of action"
   ],
   "id": "6a6a802e4ad19053",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                              title  \\\n",
      "0  304586  the wasa2 object-oriented workflow management ...   \n",
      "1  304587  a user-centered interface for querying distrib...   \n",
      "2  304589  world wide database-integrating the web, corba...   \n",
      "3  304590           xml-based information mediation with mix   \n",
      "4  304582  the ccube constraint object-oriented database ...   \n",
      "5  304583  the cornell jaguar project: adding mobility to...   \n",
      "6  304584  the active multisync controller of the cubetre...   \n",
      "7  304585                  the jungle database search engine   \n",
      "8  306112  adept: an agent-based approach to business pro...   \n",
      "9  306115  a componentized architecture for dynamic elect...   \n",
      "\n",
      "                                             authors  \\\n",
      "0                    Gottfried Vossen, Mathias Weske   \n",
      "1                  Isabel F. Cruz, Kimberly M. James   \n",
      "2  Athman Bouguettaya, Boualem Benatallah, Lily H...   \n",
      "3  Chaitan Baru, Amarnath Gupta, Bertram Lud&#228...   \n",
      "4  Alexander Brodsky, Victor E. Segal, Jia Chen, ...   \n",
      "5  Phillippe Bonnet, Kyle Buza, Zhiyuan Chan, Vic...   \n",
      "6  Nick Roussopoulos, Yannis Kotidis, Yannis Sism...   \n",
      "7  Michael B&#246;hlen, Linas Bukauskas, Curtis D...   \n",
      "8           N. R. Jennings, T. J. Norman, P. Faratin   \n",
      "9                      Benny Reich, Israel Ben-Shaul   \n",
      "\n",
      "                                            venue  year  \n",
      "0  International Conference on Management of Data  1999  \n",
      "1  International Conference on Management of Data  1999  \n",
      "2  International Conference on Management of Data  1999  \n",
      "3  International Conference on Management of Data  1999  \n",
      "4  International Conference on Management of Data  1999  \n",
      "5  International Conference on Management of Data  1999  \n",
      "6  International Conference on Management of Data  1999  \n",
      "7  International Conference on Management of Data  1999  \n",
      "8                              ACM SIGMOD Record   1998  \n",
      "9                              ACM SIGMOD Record   1998  \n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:30.000764Z",
     "start_time": "2025-10-06T20:42:29.988860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# c. Convert multiple spaces to one.\n",
    "acm1['title'] = acm1['title'].str.replace(r'\\s+', ' ', regex=True)\n",
    "dblp1['title'] = dblp1['title'].str.replace(r'\\s+', ' ', regex=True)"
   ],
   "id": "aeb03171f02bac8d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:30.018491Z",
     "start_time": "2025-10-06T20:42:30.006083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# d. Use Levenshtein similarity\n",
    "def levenshtein_similarity(s1, s2):\n",
    "    return 1 - lev.distance(s1, s2) / max(len(s1), len(s2))\n",
    "st = levenshtein_similarity(acm1['title'], dblp1['title'])\n",
    "st"
   ],
   "id": "b327f144913cd79c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013379204892966401"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:30.037918Z",
     "start_time": "2025-10-06T20:42:30.026882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# e. Use Jaro similarity\n",
    "def jaro_similarity(s1, s2):\n",
    "    return lev.jaro_winkler(s1, s2)\n",
    "sa = jaro_similarity(acm1['authors'], dblp1['authors'])\n",
    "sa"
   ],
   "id": "c2509b8d49ea0614",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3177864135767755"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:30.049698Z",
     "start_time": "2025-10-06T20:42:30.044076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#. f NOT SURE ABOUT IT: Use a modified version of the affine similarity that is scaled to the interval [0, 1]\n",
    "def scaled_affine_similarity(s1, s2, open_gap = 1, gap_ext = 0.1):\n",
    "    affine_similarity = sm.affine.Affine(gap_start = 1, gap_continuation = 0.1,\n",
    "                       sim_func = lambda s1, s2: (int(1 if s1 == s2 else 0)))\n",
    "    return affine_similarity.get_raw_score(s1, s2) / min(len(s1), len(s2))\n",
    "sv = scaled_affine_similarity(acm1.iloc[0]['venue'], dblp1.iloc[0]['venue'])\n",
    "sv"
   ],
   "id": "9ec6305e890dd2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.23076910238999587"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:30.064197Z",
     "start_time": "2025-10-06T20:42:30.061331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#. g match/mismatch\n",
    "def year_match(year1, year2):\n",
    "    if year1 == year2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "sy = year_match(acm1.iloc[0]['year'], dblp1.iloc[0]['year'])\n",
    "sy"
   ],
   "id": "7c82a597c878320",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:30.076372Z",
     "start_time": "2025-10-06T20:42:30.073862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# h. formula to combine scores to get final score\n",
    "# h. formula to combine scores to get final score\n",
    "def compare_records(rec1, rec2):\n",
    "  w1 = 0.5\n",
    "  w2 = 0.2\n",
    "  w3 = 0.2\n",
    "  w4 = 0.1\n",
    "\n",
    "  st = levenshtein_similarity(rec1.title, rec2.title)\n",
    "  sa = jaro_similarity(rec1.authors, rec2.authors)\n",
    "  sc = scaled_affine_similarity(rec1.venue, rec2.venue)\n",
    "  sy = year_match(rec1.year, rec2.year)\n",
    "\n",
    "  rec_sim = w1 * sa + w2 * st + w3 * sc + w4 * sy\n",
    "  return rec_sim"
   ],
   "id": "f4663f4cb96268f6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:30.094159Z",
     "start_time": "2025-10-06T20:42:30.089747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# i. Report the records with rec_sim > 0.7 as duplicate records by storing the ids of both records in a list.\n",
    "def record_sim(rec1, rec2,sa, st, sv, sy, threshold=0.7):\n",
    "    w1, w2, w3, w4 = 0.5, 0.2, 0.2, 0.1\n",
    "\n",
    "    rec_sim = w1 * sa + w2 * st + w3 * sv + w4 * sy\n",
    "    print(\"The similarity between the two records =\", rec_sim)\n",
    "\n",
    "    # Check if similarity exceeds threshold\n",
    "    if rec_sim > threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Example call (compare first record in each dataset)\n",
    "record_sim(acm1.iloc[0], dblp1.iloc[0],sa, st, sv, sy, 0.7)\n"
   ],
   "id": "b706b13fd44f2e6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between the two records = 0.21541522728898185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T20:42:30.141250Z",
     "start_time": "2025-10-06T20:42:30.138052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# i. Report the records with rec_sim > 0.7 as duplicate records by storing the ids of both records in a list.\n",
    "def find_duplicate_ids(df1, df2, threshold = 0.7):\n",
    "  duplicate_ids = pd.DataFrame(columns = ['idDBLP', 'idACM'])\n",
    "  for i, rec1 in df1.iterrows():\n",
    "    if(i % 100 == 0):\n",
    "      print(i)\n",
    "    for j, rec2 in df2.iterrows():\n",
    "      if compare_records(rec1, rec2) > threshold:\n",
    "        duplicate_ids.loc[len(duplicate_ids)] = [rec1.id, rec2.id]\n",
    "  return duplicate_ids\n"
   ],
   "id": "d50c545730392261",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-06T20:44:04.846045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "duplicate_ids = find_duplicate_ids(dblp, acm)\n",
    "\n",
    "matches = pd.read_csv(\"DBLP-ACM_perfectMapping.csv\")\n",
    "matches.idDBLP = matches.idDBLP.str.lower()\n",
    "\n",
    "intersection = pd.merge(duplicate_ids, matches, on=['idDBLP', 'idACM'])\n",
    "precision = len(intersection) / len(duplicate_ids)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print('elapsed time', round(elapsed_time), \"s\")\n",
    "\n",
    "duplicate_ids\n",
    "precision"
   ],
   "id": "e08484cfb2c971e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
